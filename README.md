<div align="center">
  <p>
    <a align="center" href="https://www.useocular.com/" target="_blank">
      <img
        width="850"
        src="assets/notebooks.svg"
      >
    </a>
  </p>
  <br>

  <br>
  <div align="center" style="display: flex; justify-content: center; align-items: center; margin: 20px 0;">
    <a href="https://www.linkedin.com/company/use-ocular/" style="display: flex; align-items: center; margin: 0 15px;">
        <img
          src="assets/linkedin.svg"
          width="40px"
          height="40px"
        />
    </a>
    <a href="https://www.ycombinator.com/companies/ocular-ai" style="display: flex; align-items: center; margin: 0 15px;">
        <img
          src="assets/ycombinator.svg"
          width="30px"
          height="30px"
        />
    </a>
    <a href="https://x.com/OcularHQ" style="display: flex; align-items: center; margin: 0 15px;">
        <img
          src="assets/x.svg"
          width="20px" 
          height="20px"
        />
    </a>
    <a href="https://www.youtube.com/@OcularAI" style="display: flex; align-items: center; margin: 0 15px;">
        <img
          src="assets/youtube.svg"
          width="35px" 
          height="35px"
        />
    </a>
</div>
</div>

## Ocular AI: Data Engine for The Multimodal AI Era

This repository offers a comprehensive and continuously expanding collection of tutorials, designed to help you master the latest advancements in the field. Learn how to harness powerful state-of-the-art models like YOLOv11 for real-time object detection, SAM 2 for image segmentation, Florence-2 for visual reasoning tasks, PaliGemma 2 for multimodal learning, and Qwen2.5-VL for video-language tasks. These tutorials cover a wide range of applications, including object detection, image and video segmentation, pose estimation, data extraction, and optical character recognition (OCR).


We are committed to keeping this repository up to date, and we'll be adding new notebooks regularly to cover emerging techniques and use cases. Additionally, we welcome contributions from the community, so feel free to submit your own tutorials, improvements, or ideas to help us grow this resource.


